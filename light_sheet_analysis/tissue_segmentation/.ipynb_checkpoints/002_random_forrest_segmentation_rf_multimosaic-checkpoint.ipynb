{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db987231-85eb-4a5e-b3c0-c03741164c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "np.random.seed(0)\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "import h5py\n",
    "import joblib\n",
    "import numpy as np\n",
    "from skimage import data, feature, future\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import rescale, resize\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2de31b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 1\n",
    "annotations_paths = [\n",
    "    f\"annotation_slices/MultiMosaic/Run_{x}/annotations.json\"\n",
    "    for x in range(1, run_name + 1)\n",
    "]\n",
    "all_label = []\n",
    "all_images = []\n",
    "downsample_xy = 0.25\n",
    "h5_file = True\n",
    "sigma_min = 1\n",
    "sigma_max = 256 * downsample_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f0c4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction CPU\n",
    "features_func = partial(\n",
    "    feature.multiscale_basic_features,\n",
    "    intensity=True,\n",
    "    edges=True,\n",
    "    texture=True,\n",
    "    sigma_min=sigma_min,\n",
    "    sigma_max=sigma_max,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5201315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  1.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for annotations_path in annotations_paths:\n",
    "    annotations_path = annotations_path.replace(\".json\", \"_new.json\")\n",
    "    f = open(annotations_path)\n",
    "    data = json.load(f)\n",
    "    time_ind_old = -1\n",
    "    for slice_annot in tqdm(data):\n",
    "        split_name = slice_annot.split(\".\")[0].split(\"_\")\n",
    "        slice_ind = int(split_name[5])\n",
    "        time_ind = int(split_name[3])\n",
    "        position = int(split_name[1])\n",
    "\n",
    "        if h5_file:\n",
    "            stack_file = h5py.File(\n",
    "                f\"/cluster/project/treutlein/DATA/imaging/viventis/20210503_201032_6_lines_mosaic_HB4_D4_processed/Position_{str(position)}_Settings_1_Processed/denoised_registered_processed.h5\",\n",
    "                \"r\",\n",
    "            )\n",
    "            stack_cherry = (\n",
    "                stack_file[f\"t{time_ind:05}\"][\"s00\"][\"0\"][\"cells\"][slice_ind]\n",
    "                .astype(np.float32)\n",
    "                .copy()\n",
    "            )\n",
    "            stack_gfp = (\n",
    "                stack_file[f\"t{time_ind:05}\"][\"s01\"][\"0\"][\"cells\"][slice_ind]\n",
    "                .astype(np.float32)\n",
    "                .copy()\n",
    "            )\n",
    "            img = stack_cherry + stack_gfp\n",
    "\n",
    "        img = rescale(img, [downsample_xy, downsample_xy], order=1, preserve_range=True)\n",
    "\n",
    "        training_labels = np.zeros(np.array(img.shape), dtype=np.uint8)\n",
    "        bboxes = data[slice_annot]\n",
    "        for bbox in bboxes:\n",
    "            if bbox[\"label\"] == \"background\":\n",
    "                training_labels[\n",
    "                    int(downsample_xy * bbox[\"y\"]) : (\n",
    "                        int(downsample_xy * bbox[\"y\"])\n",
    "                        + int(downsample_xy * bbox[\"height\"])\n",
    "                    ),\n",
    "                    int(downsample_xy * bbox[\"x\"]) : (\n",
    "                        int(downsample_xy * bbox[\"x\"])\n",
    "                        + int(downsample_xy * bbox[\"width\"])\n",
    "                    ),\n",
    "                ] = 1\n",
    "            if bbox[\"label\"] == \"organoid\":\n",
    "                training_labels[\n",
    "                    int(downsample_xy * bbox[\"y\"]) : (\n",
    "                        int(downsample_xy * bbox[\"y\"])\n",
    "                        + int(downsample_xy * bbox[\"height\"])\n",
    "                    ),\n",
    "                    int(downsample_xy * bbox[\"x\"]) : (\n",
    "                        int(downsample_xy * bbox[\"x\"])\n",
    "                        + int(downsample_xy * bbox[\"width\"])\n",
    "                    ),\n",
    "                ] = 2\n",
    "            if bbox[\"label\"] == \"lumen\":\n",
    "                training_labels[\n",
    "                    int(downsample_xy * bbox[\"y\"]) : (\n",
    "                        int(downsample_xy * bbox[\"y\"])\n",
    "                        + int(downsample_xy * bbox[\"height\"])\n",
    "                    ),\n",
    "                    int(downsample_xy * bbox[\"x\"]) : (\n",
    "                        int(downsample_xy * bbox[\"x\"])\n",
    "                        + int(downsample_xy * bbox[\"width\"])\n",
    "                    ),\n",
    "                ] = 3\n",
    "        # print(np.unique(training_labels))\n",
    "        # plt.imshow(img,cmap='gray')\n",
    "        # plt.imshow(training_labels, cmap='hot', alpha=0.5)\n",
    "        # plt.show()\n",
    "\n",
    "        # features = features_func(cp.asarray(img)).get()\n",
    "        features = features_func(img)\n",
    "        features = features.reshape(-1, features.shape[-1])\n",
    "        features = features[training_labels.flatten() != 0]\n",
    "        training_labels = training_labels.flatten()[training_labels.flatten() != 0]\n",
    "        time_ind_old = time_ind\n",
    "        all_images.append(features)\n",
    "        all_label.append(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f7f75df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.vstack(all_images)\n",
    "y_all = np.hstack(all_label)\n",
    "# Remove duplicates\n",
    "duplicates_indices = np.unique(X_all, axis=0, return_index=True)[1]\n",
    "X = X_all[duplicates_indices]\n",
    "y = y_all[duplicates_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ced37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=50,\n",
    "    n_jobs=-1,\n",
    "    max_depth=25,\n",
    "    max_samples=0.05,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n",
    "clf = future.fit_segmenter(y, X, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f7c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saveLook\n",
    "rf_location = \"/cluster/home/gutgi/git_repositories/morphodynamics-of-human-brain-organoid-patterning/light_sheet_analysis/tissue_segmentation/rf_classifier/\"\n",
    "if not os.path.exists(rf_location):\n",
    "    os.makedirs(rf_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc62831",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, rf_location + \"lumen_multimosaic_v15_05.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d098c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "clf = joblib.load(rf_location + \"lumen_multimosaic_v15_05.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6928fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_run = 44\n",
    "run_name = f\"Run_{annotation_run}\"\n",
    "output_dir = f\"annotation_slices/MultiMosaic/{run_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slices = 10\n",
    "positions = np.random.choice(\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], size=n_slices\n",
    ")\n",
    "random_stack_names = np.random.choice(np.arange(1, 124), size=n_slices)\n",
    "random_slice_indices = np.random.choice(np.arange(0, 231), size=n_slices)\n",
    "all_positions = [positions, random_stack_names, random_slice_indices]\n",
    "all_positions = np.unique(np.stack(all_positions, axis=1), axis=0)\n",
    "\n",
    "for position, random_stack_name, random_slice_indice in tqdm(all_positions):\n",
    "    if h5_file:\n",
    "        stack_file = h5py.File(\n",
    "            f\"/cluster/project/treutlein/DATA/imaging/viventis/20210503_201032_6_lines_mosaic_HB4_D4_processed/Position_{str(position)}_Settings_1_Processed/denoised_registered_processed.h5\",\n",
    "            \"r\",\n",
    "        )\n",
    "        random_stack_cherry = (\n",
    "            stack_file[f\"t{random_stack_name:05}\"][\"s00\"][\"0\"][\"cells\"][\n",
    "                random_slice_indice\n",
    "            ]\n",
    "            .astype(np.float32)\n",
    "            .copy()\n",
    "        )\n",
    "        random_stack_gfp = (\n",
    "            stack_file[f\"t{random_stack_name:05}\"][\"s01\"][\"0\"][\"cells\"][\n",
    "                random_slice_indice\n",
    "            ]\n",
    "            .astype(np.float32)\n",
    "            .copy()\n",
    "        )\n",
    "        random_slice = random_stack_cherry + random_stack_gfp\n",
    "        random_slice_2 = random_slice.copy()\n",
    "\n",
    "        random_slice *= 255.0 / np.percentile(random_slice.copy(), q=99.5)\n",
    "\n",
    "    else:\n",
    "        random_stack_cherry = imread(\n",
    "            input_dir\n",
    "            + f\"Position_{position}_Settings_1/denoised/mCherry/t{random_stack_name:04}_mCherry.tif\"\n",
    "        ).astype(np.float32)\n",
    "        random_stack_gfp = imread(\n",
    "            input_dir\n",
    "            + f\"Position_{position}_Settings_1/denoised/GFP/t{random_stack_name:04}_GFP.tif\"\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        random_stack = random_stack_cherry + random_stack_gfp\n",
    "        random_slice = random_stack[random_slice_indice].copy()\n",
    "\n",
    "        random_slice_2 = random_slice.copy()\n",
    "        random_slice *= 255.0 / np.percentile(random_stack.copy(), q=99.5)\n",
    "\n",
    "    random_slice_2 = rescale(\n",
    "        random_slice_2, [downsample_xy, downsample_xy], order=1, preserve_range=True\n",
    "    )\n",
    "    random_slice = random_slice.clip(0, 255)\n",
    "    image = np.stack((random_slice.astype(np.uint8),) * 3, axis=-1)\n",
    "\n",
    "    features = features_func(random_slice_2)\n",
    "    random_mask_slice = future.predict_segmenter(features, clf)\n",
    "    # random_mask_slice=postprocess_masks(random_mask_slice,min_area=128)\n",
    "    # random_mask_slice=smooth_organoids(random_mask_slice,2)\n",
    "    random_mask_slice = resize(\n",
    "        random_mask_slice, image.shape[:2], order=0, preserve_range=True\n",
    "    ).astype(\"uint8\")\n",
    "    # combine\n",
    "    colormask_organoid = np.zeros(image.shape, image.dtype)\n",
    "    colormask_organoid[:, :] = (127, 255, 0)\n",
    "    colormask_organoid = cv2.bitwise_and(\n",
    "        colormask_organoid,\n",
    "        colormask_organoid,\n",
    "        mask=(random_mask_slice == 2).astype(np.uint8),\n",
    "    )\n",
    "    image = cv2.addWeighted(colormask_organoid, 0.05, image, 1, 0, image)\n",
    "\n",
    "    colormask_lumen = np.zeros(image.shape, image.dtype)\n",
    "    colormask_lumen[:, :] = (255, 99, 71)\n",
    "    colormask_lumen = cv2.bitwise_and(\n",
    "        colormask_lumen, colormask_lumen, mask=(random_mask_slice == 3).astype(np.uint8)\n",
    "    )\n",
    "    image = cv2.addWeighted(colormask_lumen, 0.1, image, 1, 0, image)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    imsave(\n",
    "        f\"{output_dir}position_{position}_stack_{str(random_stack_name)}_slice_{str(random_slice_indice)}.jpg\",\n",
    "        image,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c31310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rapids)",
   "language": "python",
   "name": "cumcim_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from EmbedSeg.train import begin_training\n",
    "from EmbedSeg.utils.create_dicts import (\n",
    "    create_configs,\n",
    "    create_dataset_dict,\n",
    "    create_loss_dict,\n",
    "    create_model_dict,\n",
    ")\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to `train`, `val` crops and the type of `center` embedding which we would like to train the network for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-val images, masks and center-images will be accessed from the path specified by `data_dir` and `project-name`.\n",
    "<a id='center'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name chosen as : 3D_Brain_organoids_with_meta. \n",
      "Train-Val images-masks-center-images will be accessed from : /cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data//3D_Brain_organoids_with_meta/crops_all_03_03_2023\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data/\"\n",
    "project_name = \"3D_Brain_organoids_with_meta\"\n",
    "run_name = \"all_03_03_2023\"\n",
    "\n",
    "data_dir = data_dir + \"/\" + project_name + f\"/crops_{run_name}\"\n",
    "\n",
    "# project_name = '3D_Brain_organoids'\n",
    "center = \"medoid\"  # 'centroid', 'medoid'\n",
    "\n",
    "print(\n",
    "    \"Project Name chosen as : {}. \\nTrain-Val images-masks-center-images will be accessed from : {}\".format(\n",
    "        project_name, data_dir\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Embedding Location chosen as : medoid\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert center in {\"medoid\", \"centroid\"}\n",
    "    print(\"Spatial Embedding Location chosen as : {}\".format(center))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify center as one of : {\"medoid\", \"centroid\"}', 42)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain properties of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we read the `dataset.json` file prepared in the `01-data` notebook previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(f\"data_properties_{run_name}.json\"):\n",
    "    with open(f\"data_properties_{run_name}.json\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        (\n",
    "            data_type,\n",
    "            foreground_weight,\n",
    "            n_z,\n",
    "            n_y,\n",
    "            n_x,\n",
    "            pixel_size_z_microns,\n",
    "            pixel_size_x_microns,\n",
    "        ) = (\n",
    "            data[\"data_type\"],\n",
    "            float(data[\"foreground_weight\"]),\n",
    "            int(data[\"n_z\"]),\n",
    "            int(data[\"n_y\"]),\n",
    "            int(data[\"n_x\"]),\n",
    "            float(data[\"pixel_size_z_microns\"]),\n",
    "            float(data[\"pixel_size_x_microns\"]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_y = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints: \n",
    "* The `train_size` attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Ideally this should be the number of `train` image crops. \n",
    "\n",
    "In the cell after this one, a `train_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(os.listdir(os.path.join(data_dir, project_name, \"train\", \"images\")))\n",
    "train_batch_size = 8\n",
    "# virtual_batch_multiplier = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `train_dataset_dict` dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train_dataset_dict` dictionary successfully created with: \n",
      " -- train images accessed from /cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data//3D_Brain_organoids_with_meta/crops_all_03_03_2023/3D_Brain_organoids_with_meta/train/images, \n",
      " -- number of images per epoch equal to 5512, \n",
      " -- batch size set at 8, \n"
     ]
    }
   ],
   "source": [
    "train_dataset_dict = create_dataset_dict(\n",
    "    data_dir=data_dir,\n",
    "    project_name=project_name,\n",
    "    center=center,\n",
    "    size=train_size,\n",
    "    batch_size=train_batch_size,\n",
    "    # virtual_batch_multiplier = virtual_batch_multiplier,\n",
    "    type=\"train\",\n",
    "    name=\"3d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify validation dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The size attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Here, it is recommended to set `val_size` equal to the total number of validation image crops.\n",
    "\n",
    "In the cell after this one, a `val_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = len(os.listdir(os.path.join(data_dir, project_name, \"val\", \"images\")))\n",
    "val_batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `val_dataset_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`val_dataset_dict` dictionary successfully created with: \n",
      " -- val images accessed from /cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data//3D_Brain_organoids_with_meta/crops_all_03_03_2023/3D_Brain_organoids_with_meta/val/images, \n",
      " -- number of images per epoch equal to 338, \n",
      " -- batch size set at 16, \n"
     ]
    }
   ],
   "source": [
    "val_dataset_dict = create_dataset_dict(\n",
    "    data_dir=data_dir,\n",
    "    project_name=project_name,\n",
    "    center=center,\n",
    "    size=val_size,\n",
    "    batch_size=val_batch_size,\n",
    "    type=\"val\",\n",
    "    name=\"3d\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify model-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* Set the `input_channels` attribute equal to the number of channels in the input images. \n",
    "* Set the `num_classes = [6, 1]` for `3d` training and `num_classes = [4, 1]` for `2d` training\n",
    "<br>(here, 6 implies the offsets and bandwidths in x, y and z dimensions and 1 implies the `seediness` value per pixel)\n",
    "\n",
    "In the cell after this one, a `model_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = [6, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `model_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`model_dict` dictionary successfully created with: \n",
      " -- num of classes equal to 1, \n",
      " -- input channels equal to [6, 1], \n",
      " -- name equal to branched_erfnet_3d\n"
     ]
    }
   ],
   "source": [
    "model_dict = create_model_dict(\n",
    "    input_channels=input_channels, num_classes=num_classes, name=\"3d\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `loss_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`loss_dict` dictionary successfully created with: \n",
      " -- foreground weight equal to 48.009, \n",
      " -- w_inst equal to 1, \n",
      " -- w_var equal to 10, \n",
      " -- w_seed equal to 1\n"
     ]
    }
   ],
   "source": [
    "loss_dict = create_loss_dict(n_sigma=3, foreground_weight=foreground_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify additional parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The `n_epochs` attribute determines how long the training should proceed. In general for reasonable results, you should atleast train for longer than 50 epochs.\n",
    "* The `save_dir` attribute identifies the location where the checkpoints and loss curve details are saved. \n",
    "* If one wishes to **resume training** from a previous checkpoint, they could point `resume_path` attribute appropriately. For example, one could set `resume_path = './experiment/Mouse-Organoid-Cells-CBG-demo/checkpoint.pth'` to resume training from the last checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "save_dir = os.path.join(\"experiment\", project_name + \"-\" + run_name)\n",
    "resume_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell after this one, a `configs` dictionary is generated from the parameters specified here!\n",
    "<a id='resume'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the  `configs` dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`configs` dictionary successfully created with: \n",
      " -- n_epochs equal to 210, \n",
      " -- save_dir equal to experiment/3D_Brain_organoids_with_meta-all_03_03_2023_resumed_v3, \n",
      " -- n_z equal to 80, \n",
      " -- n_y equal to 600, \n",
      " -- n_x equal to 600, \n"
     ]
    }
   ],
   "source": [
    "configs = create_configs(\n",
    "    n_epochs=n_epochs,\n",
    "    resume_path=resume_path,\n",
    "    save_dir=save_dir,\n",
    "    n_z=n_z,\n",
    "    n_y=n_y,\n",
    "    n_x=n_x,\n",
    "    # train_lr=5e-4,\n",
    "    anisotropy_factor=pixel_size_z_microns / pixel_size_x_microns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the next cell would begin the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-D `train` dataloader created! Accessing data from /cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data//3D_Brain_organoids_with_meta/crops_all_03_03_2023/3D_Brain_organoids_with_meta/train/\n",
      "Number of images in `train` directory is 5512\n",
      "Number of instances in `train` directory is 5512\n",
      "Number of center images in `train` directory is 5512\n",
      "*************************\n",
      "3-D `val` dataloader created! Accessing data from /cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data//3D_Brain_organoids_with_meta/crops_all_03_03_2023/3D_Brain_organoids_with_meta/val/\n",
      "Number of images in `val` directory is 338\n",
      "Number of instances in `val` directory is 338\n",
      "Number of center images in `val` directory is 338\n",
      "*************************\n",
      "Creating Branched Erfnet 3D with [6, 1] outputs\n",
      "initialize last layer with size:  torch.Size([16, 6, 2, 2, 2])\n",
      "Created spatial emb loss function with: n_sigma: 3, foreground_weight: 48.00866531190462\n",
      "*************************\n",
      "Created logger with keys:  ('train', 'val', 'iou')\n",
      "Resuming model from experiment/3D_Brain_organoids_pretraining-all_29_03_2023_pretraining_V2/checkpoint.pth\n",
      "Starting epoch 122\n",
      "learning rate: 0.00022856358747947857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [11:43<00:00,  1.02s/it]\n",
      "100%|██████████| 22/22 [00:18<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.96\n",
      "===> val loss: 0.85, val iou: 0.66\n",
      "=> saving checkpoint\n",
      "Starting epoch 123\n",
      "learning rate: 0.00022622467159583027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [11:57<00:00,  1.04s/it]\n",
      "100%|██████████| 22/22 [00:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.87\n",
      "===> val loss: 0.84, val iou: 0.67\n",
      "=> saving checkpoint\n",
      "Starting epoch 124\n",
      "learning rate: 0.0002238830656952329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [11:53<00:00,  1.04s/it]\n",
      "100%|██████████| 22/22 [00:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.83\n",
      "===> val loss: 0.84, val iou: 0.67\n",
      "=> saving checkpoint\n",
      "Starting epoch 125\n",
      "learning rate: 0.00022153873534893717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 142/689 [02:23<08:52,  1.03it/s]"
     ]
    }
   ],
   "source": [
    "begin_training(train_dataset_dict, val_dataset_dict, model_dict, loss_dict, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "  Common causes for errors during training, may include : <br>\n",
    "    1. Not having <b>center images</b> for  <b>both</b> train and val directories  <br>\n",
    "    2. <b>Mismatch</b> between type of center-images saved in <b>01-data.ipynb</b> and the type of center chosen in this notebook (see the <b><a href=\"#center\"> center</a></b> parameter in the third code cell in this notebook)   <br>\n",
    "    3. In case of resuming training from a previous checkpoint, please ensure that the model weights are read from the correct directory, using the <b><a href=\"#resume\"> resume_path</a></b> parameter. Additionally, please ensure that the <b>save_dir</b> parameter for saving the model weights points to a relevant directory. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\n",
    "    \"experiment\", project_name + \"-\" + run_name, \"best_iou_model.pth\"\n",
    ")\n",
    "if os.path.isfile(\"data_properties.json\"):\n",
    "    with open(os.path.join(\"data_properties_{run_name}.json\")) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        one_hot = data[\"one_hot\"]\n",
    "        data_type = data[\"data_type\"]\n",
    "        min_object_size = int(data[\"min_object_size\"])\n",
    "        # foreground_weight = float(data['foreground_weight'])\n",
    "        # n_z, n_y, n_x = int(data['n_z']),int(data['n_y']), int(data['n_x'])\n",
    "        pixel_size_z_microns, pixel_size_y_microns, pixel_size_x_microns = (\n",
    "            float(data[\"pixel_size_z_microns\"]),\n",
    "            float(data[\"pixel_size_y_microns\"]),\n",
    "            float(data[\"pixel_size_x_microns\"]),\n",
    "        )\n",
    "        # mask_start_x, mask_start_y, mask_start_z = 700,700,160\n",
    "        # mask_end_x, mask_end_y, mask_end_z =  800,800,200\n",
    "if os.path.isfile(f\"normalization_{run_name}.json\"):\n",
    "    with open(os.path.join(f\"normalization_{run_name}.json\")) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        norm = data[\"norm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Trained model weights found at : {}\".format(checkpoint_path))\n",
    "else:\n",
    "    print(\"Trained model weights were not found at the specified location!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = True\n",
    "ap_val = 0.5\n",
    "data_dir = \"/cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data/\"\n",
    "project_name = \"3D_Brain_organoids\"\n",
    "save_dir = data_dir + \"/\" + project_name + f\"/3D_one_image_per_day_{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmbedSeg.test import begin_evaluating, test_3d\n",
    "from EmbedSeg.utils.create_dicts import create_test_configs_dict\n",
    "\n",
    "test_configs = create_test_configs_dict(\n",
    "    data_dir=os.path.join(data_dir, project_name),\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    tta=tta,\n",
    "    ap_val=ap_val,\n",
    "    min_object_size=min_object_size,\n",
    "    save_dir=save_dir,\n",
    "    norm=norm,\n",
    "    data_type=data_type,\n",
    "    n_z=n_z,\n",
    "    n_y=n_y,\n",
    "    type=\"3D_one_image_per_day\",\n",
    "    n_x=n_x,\n",
    "    anisotropy_factor=pixel_size_z_microns / pixel_size_x_microns,\n",
    "    name=\"3d\",\n",
    "    seed_thresh=0.7,\n",
    "    fg_thresh=0.4,\n",
    "    expand_grid=False,\n",
    ")\n",
    "begin_evaluating(test_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = True\n",
    "ap_val = 0.5\n",
    "data_dir = \"/cluster/project/treutlein/DATA/imaging/EmbedSeg_test/data/\"\n",
    "\n",
    "save_dir = data_dir + \"/\" + project_name + f\"/3D_one_image_per_day_AGAR_{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EmbedSeg.test import begin_evaluating, test_3d\n",
    "from EmbedSeg.utils.create_dicts import create_test_configs_dict\n",
    "\n",
    "test_configs = create_test_configs_dict(\n",
    "    data_dir=os.path.join(data_dir, project_name),\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    tta=tta,\n",
    "    ap_val=ap_val,\n",
    "    min_object_size=min_object_size,\n",
    "    save_dir=save_dir,\n",
    "    norm=norm,\n",
    "    data_type=data_type,\n",
    "    n_z=n_z,\n",
    "    n_y=n_y,\n",
    "    type=\"3D_one_image_per_day_AGAR\",\n",
    "    n_x=n_x,\n",
    "    anisotropy_factor=pixel_size_z_microns / pixel_size_x_microns,\n",
    "    name=\"3d\",\n",
    "    seed_thresh=0.7,\n",
    "    fg_thresh=0.4,\n",
    "    expand_grid=False,\n",
    ")\n",
    "begin_evaluating(test_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (EmbedSeg)",
   "language": "python",
   "name": "embedsegenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
